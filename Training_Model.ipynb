{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6c3a986",
      "metadata": {
        "id": "d6c3a986"
      },
      "source": [
        "# Setup paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgEo-1ZPKht7",
        "outputId": "8a877e67-072b-46b4-d548-4d7e6afae885"
      },
      "id": "FgEo-1ZPKht7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqtiqFpdKonh",
        "outputId": "d1496ca7-62d9-4997-a9da-692589a1f2a7"
      },
      "id": "TqtiqFpdKonh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OeppT_yKw7y",
        "outputId": "658a51cd-12b5-433a-cc60-aaca5a838728"
      },
      "id": "1OeppT_yKw7y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/11Nbvfv2gDXwVgOrqKSOW69hmt_-zSksQ/TFODCourse - Copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a50019",
      "metadata": {
        "id": "02a50019"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf '/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy/Tensorflow/workspace/models/drone_ssd_mobnet'"
      ],
      "metadata": {
        "id": "kLBFVWjOThul"
      },
      "id": "kLBFVWjOThul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c851ba",
      "metadata": {
        "id": "d3c851ba"
      },
      "outputs": [],
      "source": [
        "# define global variables\n",
        "CUSTOM_MODEL_NAME = 'drone_ssd_mobnet_v4'\n",
        "# http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{PRETRAINED_MODEL_NAME}.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map_2.pbtxt'\n",
        "BATCH_SIZE = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34cc0d5",
      "metadata": {
        "id": "d34cc0d5"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    \"WORKSPACE_PATH\" : os.path.join('Tensorflow', 'workspace'),\n",
        "    \"SCRIPTS_PATH\" : os.path.join('Tensorflow', 'scripts'),\n",
        "    \"APIMODEL_PATH\" : os.path.join('Tensorflow', 'models'),\n",
        "    \"ANNOTATION_PATH\" : os.path.join('Tensorflow', 'workspace', 'annotations'),\n",
        "    \"IMAGE_PATH\" : os.path.join('Tensorflow', 'workspace', 'images'),\n",
        "    \"MODEL_PATH\" : os.path.join('Tensorflow', 'workspace', 'models'),\n",
        "    \"PRETRAINED_MODEL_PATH\" : os.path.join('Tensorflow', 'workspace', 'pre-trained-models'),\n",
        "    \"CHECKPOINT_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
        "    \"OUTPUT_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'),\n",
        "    \"TFJS_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    \"TFLITE_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    \"PROTOC_PATH\" : os.path.join('Tensorflow', 'protoc'),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf128a90",
      "metadata": {
        "id": "bf128a90"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG' : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT' : os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP' : os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc58974b",
      "metadata": {
        "id": "fc58974b"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train-test"
      ],
      "metadata": {
        "id": "mj2dnCQYfD-0"
      },
      "id": "mj2dnCQYfD-0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50ad3b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50ad3b1",
        "outputId": "cb1393dd-ac67-4236-ec53-2120e95dac8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n"
          ]
        }
      ],
      "source": [
        "xmls = glob.glob(\"Tensorflow/workspace/images/dataset_xml_format/*.xml\")\n",
        "pngs = glob.glob(\"Tensorflow/workspace/images/dataset_xml_format/*.png\")\n",
        "jpgs = glob.glob(\"Tensorflow/workspace/images/dataset_xml_format/*.jpg\")\n",
        "imgs = pngs + jpgs\n",
        "\n",
        "print(len(imgs), len(xmls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed74d630",
      "metadata": {
        "id": "ed74d630"
      },
      "outputs": [],
      "source": [
        "os.mkdir('Tensorflow/workspace/images/train')\n",
        "os.mkdir('Tensorflow/workspace/images/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "463f94d8",
      "metadata": {
        "id": "463f94d8"
      },
      "outputs": [],
      "source": [
        "for img in sorted(imgs)[:len(imgs) // 5]:\n",
        "    x = img.split('.')[0] + \".xml\"\n",
        "    if x in xmls:\n",
        "        os.rename(x, x.replace(\"dataset_xml_format\", \"test\"))\n",
        "        os.rename(img, img.replace(\"dataset_xml_format\", \"test\"))\n",
        "    else:\n",
        "        print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd0959dd",
      "metadata": {
        "id": "bd0959dd"
      },
      "outputs": [],
      "source": [
        "for img in sorted(imgs)[len(imgs) // 5:]:\n",
        "    x = img.split('.')[0] + \".xml\"\n",
        "    if x in xmls:\n",
        "        os.rename(x, x.replace(\"dataset_xml_format\", \"train\"))\n",
        "        os.rename(img, img.replace(\"dataset_xml_format\", \"train\"))\n",
        "    else:\n",
        "        print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9f3e08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9f3e08",
        "outputId": "29e5357f-fcb4-4479-e1c0-f2f6499a9212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n"
          ]
        }
      ],
      "source": [
        "train_xmls = glob.glob(\"Tensorflow/workspace/images/train/*.xml\")\n",
        "test_xmls = glob.glob(\"Tensorflow/workspace/images/test/*.xml\")\n",
        "\n",
        "print(len(train_xmls), len(test_xmls))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c917f2",
      "metadata": {
        "id": "00c917f2"
      },
      "source": [
        "# Download Models from TF Model ZOO and install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f688dc54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f688dc54",
        "outputId": "2d40421a-71f2-468f-c4c3-0f2f40664e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 3.19.6\n",
            "Uninstalling protobuf-3.19.6:\n",
            "  Successfully uninstalled protobuf-3.19.6\n",
            "Found existing installation: matplotlib 3.2.2\n",
            "Uninstalling matplotlib-3.2.2:\n",
            "  Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip -q install protobuf \n",
        "!pip -q install matplotlib\n",
        "!pip -q install tensorflow\n",
        "!pip -q install tensorflow-addons\n",
        "!pip -q install pyyaml\n",
        "!pip -q install gin-config\n",
        "!pip -q install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa8520c",
      "metadata": {
        "id": "aaa8520c"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf '/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy/Tensorflow/models'"
      ],
      "metadata": {
        "id": "yxAYJlXXiUx3"
      },
      "id": "yxAYJlXXiUx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8ae6ca",
      "metadata": {
        "id": "ba8ae6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09757e5b-1654-4ccb-a336-9f3de3f722d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 80657, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 80657 (delta 109), reused 164 (delta 96), pack-reused 80473\u001b[K\n",
            "Receiving objects: 100% (80657/80657), 594.59 MiB | 16.35 MiB/s, done.\n",
            "Resolving deltas: 100% (57470/57470), done.\n",
            "Updating files: 100% (3320/3320), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122f2b41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "122f2b41",
        "outputId": "96c98b2e-0838-44f1-b51b-87dc153673ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/.shortcut-targets-by-id/11Nbvfv2gDXwVgOrqKSOW69hmt_-zSksQ/TFODCourse - Copy/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.6.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.29.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (1.0.7)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.29.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21919980 sha256=c506bbddaa3410e2525d35d1b533a33f526c602741970d0e720e5e1fc11b55fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fg19o4p_/wheels/50/7c/05/e422135a751174d113e22e42ef7205883e16a7e8888745a072\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=e21631bb0d376c7d6917a0ca8ee64204d1a9af95848d760f96f2005a9666aec3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=08d4f99e081926fa7559621a15fe0b688465937ff06bd82ebc5dc67f84cc05ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=96a9930f6196beeaf72a938f6110b28ad34a10822c3937e6fe9a3b2ee3913361\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=087d2e403fd7515dcf708718d6a0aa16fc8e5910aab99be40240de50e424e56b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, flatbuffers, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, apache-beam, tensorboard, lvis, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed apache-beam-2.44.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 flatbuffers-23.1.4 hdfs-2.7.0 immutabledict-2.2.3 keras-2.11.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.5 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.29.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ],
      "source": [
        "# Install tf object-detection\n",
        "if os.name == 'posix':\n",
        "    !apt install protobuf-compiler\n",
        "    script = f'cd Tensorflow/models/research && \\\n",
        "    protoc object_detection/protos/*.proto --python_out=. && \\\n",
        "    cp object_detection/packages/tf2/setup.py . && \\\n",
        "    python -m pip install .'\n",
        "    !{script}\n",
        "\n",
        "if os.name == 'nt':\n",
        "    url = \"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    \n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    \n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    \n",
        "    script = f'cd Tensorflow/models/research && \\\n",
        "    protoc object_detection/protos/*.proto --python_out=. && \\\n",
        "    copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && \\\n",
        "    python setup.py build && \\\n",
        "    python setup.py install'\n",
        "    !{script}\n",
        "    \n",
        "    !cd Tensorflow/models/research/slim && pip install -e # (--editable) Install a project from a local project path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fde3d17",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fde3d17",
        "outputId": "6b92f508-6d1e-4b53-a943-c57871b7e23b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py: Permission denied\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(\n",
        "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py'\n",
        ")\n",
        "# Verify instalation\n",
        "!{VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc2cc2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc2cc2a",
        "outputId": "3995b38b-20d4-4b42-b36e-86aa15f1ee67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-21 12:42:02--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.145.128, 2a00:1450:4013:c07::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.145.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  97.8MB/s    in 0.2s    \n",
            "\n",
            "2023-01-21 12:42:02 (97.8 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name == 'posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME + '.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME + '.tar.gz'}\n",
        "\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME + '.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME + '.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3515cfb7",
      "metadata": {
        "id": "3515cfb7"
      },
      "source": [
        "# Create label map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365dfb2b",
      "metadata": {
        "id": "365dfb2b"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "    {'name' : 'drone', 'id' : 1}, \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57eb385e",
      "metadata": {
        "id": "57eb385e"
      },
      "outputs": [],
      "source": [
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write(f'\\tname:\\'{label[\"name\"]}\\'\\n')\n",
        "        f.write(f'\\tid:{label[\"id\"]}\\n')\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9354e180",
      "metadata": {
        "id": "9354e180"
      },
      "source": [
        "# Create TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9b627e",
      "metadata": {
        "id": "2c9b627e"
      },
      "outputs": [],
      "source": [
        "# need to correct extensions for xml files:\n",
        "\n",
        "train_xmls = glob.glob(\"Tensorflow/workspace/images/train/*.xml\")\n",
        "train_pngs = glob.glob(\"Tensorflow/workspace/images/train/*.png\")\n",
        "train_jpgs = glob.glob(\"Tensorflow/workspace/images/train/*.jpg\")\n",
        "train_imgs = train_pngs + train_jpgs\n",
        "\n",
        "for x in sorted(train_xmls):\n",
        "    \n",
        "    if x.split('.')[0] + '.jpg' in train_imgs:\n",
        "        extension = os.path.split(x.split('.')[0] + '.jpg')[-1]\n",
        "    if x.split('.')[0] + '.png' in train_imgs:\n",
        "        extension = os.path.split(x.split('.')[0] + '.png')[-1]\n",
        "    \n",
        "#     print(extension)\n",
        "    \n",
        "#     print(x)\n",
        "    with open(x, 'r') as xml_file:\n",
        "        data = xml_file.read()\n",
        "        \n",
        "        \n",
        "    tree = ET.parse(x)\n",
        "    root = tree.getroot()\n",
        "    elem = root.findall('filename')\n",
        "    for i in elem:\n",
        "        txt_replace = i.text\n",
        "\n",
        "    correct_data = data.replace(txt_replace, extension)\n",
        "    \n",
        "    with open(x, 'w') as xml_file:\n",
        "        xml_file.write(correct_data)\n",
        "        \n",
        "#     print(data.replace(txt_replace, extension))\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f043481",
      "metadata": {
        "id": "7f043481"
      },
      "outputs": [],
      "source": [
        "# Optionally if running in colab\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "    print('tar:')\n",
        "    !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e53995",
      "metadata": {
        "id": "91e53995"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9cbbc8",
      "metadata": {
        "scrolled": true,
        "id": "4e9cbbc8",
        "outputId": "3f5d7adb-e762-4135-a2a1-c939e3b8b0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n",
            "Tensorflow\\workspace\\annotations\\train.record\n"
          ]
        }
      ],
      "source": [
        "script = f'\\\n",
        "python {files[\"TF_RECORD_SCRIPT\"]} \\\n",
        "-x {os.path.join(paths[\"IMAGE_PATH\"], \"train\")} \\\n",
        "-l {files[\"LABELMAP\"]} \\\n",
        "-o {os.path.join(paths[\"ANNOTATION_PATH\"], \"train.record\")}'\n",
        "!{script}\n",
        "\n",
        "print(os.path.join(paths[\"ANNOTATION_PATH\"], \"train.record\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c153fc3d",
      "metadata": {
        "id": "c153fc3d",
        "outputId": "eefaf827-828c-4e5e-ef6b-4b07dd55d4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n",
            "Tensorflow\\workspace\\annotations\\test.record\n"
          ]
        }
      ],
      "source": [
        "script = f'\\\n",
        "python {files[\"TF_RECORD_SCRIPT\"]} \\\n",
        "-x {os.path.join(paths[\"IMAGE_PATH\"], \"test\")} \\\n",
        "-l {files[\"LABELMAP\"]} \\\n",
        "-o {os.path.join(paths[\"ANNOTATION_PATH\"], \"test.record\")}'\n",
        "!{script}\n",
        "\n",
        "print(os.path.join(paths[\"ANNOTATION_PATH\"], \"test.record\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1756dd7c",
      "metadata": {
        "id": "1756dd7c"
      },
      "source": [
        "# Copy model config to train folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !rm {os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config')}\n",
        "# !cp '/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy/Tensorflow/workspace/models/drone_ssd_mobnet_v3/pipeline.config' {os.path.join(paths['CHECKPOINT_PATH'])}\n"
      ],
      "metadata": {
        "id": "57jCr6x_x3L9"
      },
      "id": "57jCr6x_x3L9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb115336",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb115336",
        "outputId": "26546594-35f3-4919-f25b-8dee3facc299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'Tensorflow/workspace/models/drone_ssd_mobnet_v4/pipeline.config': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "if os.name == 'posix':\n",
        "    !rm {os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config')}\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "\n",
        "if os.name == 'nt':\n",
        "    !del {os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config')}\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cf4b4d",
      "metadata": {
        "id": "53cf4b4d"
      },
      "source": [
        "# Update config for transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c7a038",
      "metadata": {
        "id": "a5c7a038"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import object_detection.utils.config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c748e1",
      "metadata": {
        "id": "94c748e1"
      },
      "outputs": [],
      "source": [
        "model_config = object_detection.utils.config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c721e428",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c721e428",
        "outputId": "f8d7233a-8748-4554-c42d-12f323bcf4b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 1\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " }, 'train_config': batch_size: 4\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.25\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   adam_optimizer {\n",
              "     learning_rate {\n",
              "       exponential_decay_learning_rate {\n",
              "         initial_learning_rate: 0.0010000000474974513\n",
              "         decay_steps: 3000\n",
              "         decay_factor: 0.8999999761581421\n",
              "       }\n",
              "     }\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"detection\"\n",
              " fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map_2.pbtxt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              " }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false, 'eval_input_configs': [label_map_path: \"Tensorflow/workspace/annotations/label_map_2.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }\n",
              " ], 'eval_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map_2.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "model_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce68777",
      "metadata": {
        "id": "6ce68777"
      },
      "outputs": [],
      "source": [
        "pipeline_config = object_detection.protos.pipeline_pb2.TrainEvalPipelineConfig()\n",
        "\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], 'r') as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f73184",
      "metadata": {
        "id": "f1f73184"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "\n",
        "pipeline_config.train_config.batch_size = BATCH_SIZE\n",
        "\n",
        "# https://github.com/tensorflow/models/blob/master/research/object_detection/protos/optimizer.proto\n",
        "# rms_prop_optimizer\n",
        "# momentum_optimizer\n",
        "# adam_optimizer\n",
        "# And then for each optimizer, you can configure the learning rate as one of the following\n",
        "# constant_learning_rate\n",
        "# exponential_decay_learning_rate\n",
        "# manual_step_learning_rate\n",
        "# cosine_decay_learning_rate\n",
        "\n",
        "\n",
        "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.constant_learning_rate.learning_rate = 0.001\n",
        "\n",
        "\n",
        "# pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = 0.05\n",
        "# pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = 0.025\n",
        "\n",
        "\n",
        "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.exponential_decay_learning_rate.initial_learning_rate = 0.000015\n",
        "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_steps = 3000\n",
        "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_factor = 0.9\n",
        "\n",
        "# pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = 0.05\n",
        "# pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = 0.025\n",
        "\n",
        "pipeline_config.train_config.data_augmentation_options[1].random_crop_image.min_object_covered = 0.25\n",
        "\n",
        "\n",
        "\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(\n",
        "    paths['PRETRAINED_MODEL_PATH'], \n",
        "    PRETRAINED_MODEL_NAME, \n",
        "    'checkpoint', \n",
        "    'ckpt-0'\n",
        ")\n",
        "\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
        "    os.path.join(paths['ANNOTATION_PATH'], 'train.record')\n",
        "]\n",
        "\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
        "    os.path.join(paths['ANNOTATION_PATH'], 'test.record')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline_config.train_config.fine_tune_checkpoint = \"/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy/Tensorflow/workspace/models/drone_ssd_mobnet_v3/ckpt-85\""
      ],
      "metadata": {
        "id": "9BbtmZW2trd6"
      },
      "id": "9BbtmZW2trd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.join(\n",
        "    paths['PRETRAINED_MODEL_PATH'], \n",
        "    PRETRAINED_MODEL_NAME, \n",
        "    'checkpoint', \n",
        "    'ckpt-0'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DW1zuo52Q5G2",
        "outputId": "a00c4eed-4bda-4fb6-87eb-3e60355c8355"
      },
      "id": "DW1zuo52Q5G2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09e45c20",
      "metadata": {
        "id": "09e45c20"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], 'wb') as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70edde76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70edde76",
        "outputId": "3f22b955-1546-4260-963b-53b522f707c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 1\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 320\n",
              "        width: 320\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.25\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    adam_optimizer {\n",
              "      learning_rate {\n",
              "        exponential_decay_learning_rate {\n",
              "          initial_learning_rate: 1.4999999621068127e-05\n",
              "          decay_steps: 3000\n",
              "          decay_factor: 0.8999999761581421\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map_2.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"Tensorflow/workspace/annotations/label_map_2.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "pipeline_config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9d01c3",
      "metadata": {
        "id": "fb9d01c3"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241be79f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "241be79f",
        "outputId": "dead087c-dbc5-4a96-88d3-34c226a32c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
        "print(os.path.exists(TRAINING_SCRIPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce04921",
      "metadata": {
        "id": "1ce04921"
      },
      "outputs": [],
      "source": [
        "script = f\"python {TRAINING_SCRIPT} \\\n",
        "--model_dir={paths['CHECKPOINT_PATH']} \\\n",
        "--pipeline_config_path={files['PIPELINE_CONFIG']} \\\n",
        "--num_train_steps=30000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71abec5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71abec5c",
        "outputId": "148c24e3-5b70-453f-daca-b7c7bd83a624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/drone_ssd_mobnet_v4 --pipeline_config_path=Tensorflow/workspace/models/drone_ssd_mobnet_v4/pipeline.config --num_train_steps=30000\n"
          ]
        }
      ],
      "source": [
        "# run in terminal\n",
        "print(script)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{script}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO_1vF_ELr-I",
        "outputId": "9e5e1a48-7943-47cd-dea7-0e98c4d25876"
      },
      "id": "UO_1vF_ELr-I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-21 14:43:45.921172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:43:45.921277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:43:45.921296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-01-21 14:43:49.624031: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0121 14:43:49.646665 140695257488448 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 30000\n",
            "I0121 14:43:49.655210 140695257488448 config_util.py:552] Maybe overwriting train_steps: 30000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0121 14:43:49.655423 140695257488448 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0121 14:43:49.696056 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0121 14:43:49.719795 140695257488448 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0121 14:43:49.720220 140695257488448 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0121 14:43:49.720356 140695257488448 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0121 14:43:49.721014 140695257488448 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0121 14:43:49.735215 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0121 14:43:49.777405 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0121 14:43:50.903309 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0121 14:43:58.982579 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0121 14:44:01.456244 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0121 14:44:02.822244 140695257488448 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "W0121 14:44:29.236862 140695257488448 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "W0121 14:44:29.237087 140695257488448 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "W0121 14:44:29.237167 140695257488448 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "W0121 14:44:29.237229 140695257488448 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "W0121 14:44:29.237286 140695257488448 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55bbe7cd",
      "metadata": {
        "id": "55bbe7cd"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9112adc4",
      "metadata": {
        "id": "9112adc4"
      },
      "outputs": [],
      "source": [
        "script = f\"python {TRAINING_SCRIPT} \\\n",
        "--model_dir={paths['CHECKPOINT_PATH']} \\\n",
        "--pipeline_config_path={files['PIPELINE_CONFIG']} \\\n",
        "--checkpoint_dir={paths['CHECKPOINT_PATH']}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9c46ef",
      "metadata": {
        "id": "ac9c46ef",
        "outputId": "188515e6-51bc-43c8-c62b-49120e8a239c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\new_ssd_mobnet --pipeline_config=Tensorflow\\workspace\\models\\new_ssd_mobnet\\pipeline.config --checkpoint_dir=Tensorflow\\workspace\\models\\new_ssd_mobnet\n"
          ]
        }
      ],
      "source": [
        "print(script)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b1f4ec4",
      "metadata": {
        "id": "3b1f4ec4"
      },
      "source": [
        "# Load model from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/TFODCourse - Copy/Tensorflow/models/research')"
      ],
      "metadata": {
        "id": "McBNSwcJfnjK"
      },
      "id": "McBNSwcJfnjK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b35de3e",
      "metadata": {
        "id": "7b35de3e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util, config_util, visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c08865",
      "metadata": {
        "id": "d1c08865"
      },
      "outputs": [],
      "source": [
        "# load pipeline config and build model\n",
        "model_config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=model_config['model'], is_training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fafcc90",
      "metadata": {
        "id": "5fafcc90",
        "outputId": "64f93a8d-2928-451c-e297-ec9b4f315c2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1c58b6142b0>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# restore checkpoint\n",
        "ckpt = tf.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b970bb47",
      "metadata": {
        "id": "b970bb47"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abba06ed",
      "metadata": {
        "id": "abba06ed"
      },
      "source": [
        "# Detect from an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9649ee6",
      "metadata": {
        "id": "d9649ee6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "076317c7",
      "metadata": {
        "id": "076317c7"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "732bd6c5",
      "metadata": {
        "id": "732bd6c5"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'thumbsup.a53e7a1f-86c4-11ec-a413-4cebbd6edeae.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5caa9e80",
      "metadata": {
        "id": "5caa9e80",
        "outputId": "170193e9-56a4-4d02-80d2-382688f82638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['livelong.c4207e43-86c4-11ec-9952-4cebbd6edeae.jpg',\n",
              " 'livelong.c4207e43-86c4-11ec-9952-4cebbd6edeae.xml',\n",
              " 'thankyou.baf58ad3-86c4-11ec-869a-4cebbd6edeae.jpg',\n",
              " 'thankyou.baf58ad3-86c4-11ec-869a-4cebbd6edeae.xml',\n",
              " 'thumbsdown.b09fccf7-86c4-11ec-92a5-4cebbd6edeae.jpg',\n",
              " 'thumbsdown.b09fccf7-86c4-11ec-92a5-4cebbd6edeae.xml',\n",
              " 'thumbsup.a53e7a1f-86c4-11ec-a413-4cebbd6edeae.jpg',\n",
              " 'thumbsup.a53e7a1f-86c4-11ec-a413-4cebbd6edeae.xml']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(os.path.join(paths['IMAGE_PATH'], 'test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748d4eb2",
      "metadata": {
        "id": "748d4eb2"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(img, 0), dtype=tf.float32)\n",
        "\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {\n",
        "    key : value[0, :num_detections].numpy()\n",
        "    for key, value in detections.items()\n",
        "}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be int\n",
        "detections['detection_classes'] = detections['detection_classes'].astype('int')\n",
        "\n",
        "label_id_offset = 1\n",
        "img_detections = img.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    img_detections,\n",
        "    detections['detection_boxes'],\n",
        "    detections['detection_classes'] + label_id_offset,\n",
        "    detections['detection_scores'],\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    max_boxes_to_draw=5,\n",
        "    min_score_thresh=0.7,\n",
        "    agnostic_mode=False\n",
        ")\n",
        "\n",
        "plt.imshow(img_detections[..., ::-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efc5ab8",
      "metadata": {
        "id": "2efc5ab8"
      },
      "source": [
        "# Real time detection from webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b893efe",
      "metadata": {
        "scrolled": false,
        "id": "1b893efe"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import object_detection\n",
        "from object_detection.utils import label_map_util, config_util, visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections\n",
        "\n",
        "# define global variables\n",
        "CUSTOM_MODEL_NAME = 'new_ssd_mobnet'\n",
        "# http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{PRETRAINED_MODEL_NAME}.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map_2.pbtxt'\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "paths = {\n",
        "    \"WORKSPACE_PATH\" : os.path.join('Tensorflow', 'workspace'),\n",
        "    \"SCRIPTS_PATH\" : os.path.join('Tensorflow', 'scripts'),\n",
        "    \"APIMODEL_PATH\" : os.path.join('Tensorflow', 'models'),\n",
        "    \"ANNOTATION_PATH\" : os.path.join('Tensorflow', 'workspace', 'annotations'),\n",
        "    \"IMAGE_PATH\" : os.path.join('Tensorflow', 'workspace', 'images'),\n",
        "    \"MODEL_PATH\" : os.path.join('Tensorflow', 'workspace', 'models'),\n",
        "    \"PRETRAINED_MODEL_PATH\" : os.path.join('Tensorflow', 'workspace', 'pre-trained-models'),\n",
        "    \"CHECKPOINT_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
        "    \"OUTPUT_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'),\n",
        "    \"TFJS_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    \"TFLITE_PATH\" : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    \"PROTOC_PATH\" : os.path.join('Tensorflow', 'protoc'),\n",
        "}\n",
        "files = {\n",
        "    'PIPELINE_CONFIG' : os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT' : os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP' : os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME),\n",
        "}\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
        "\n",
        "# load pipeline config and build model\n",
        "model_config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=model_config['model'], is_training=False)\n",
        "# restore checkpoint\n",
        "ckpt = tf.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
        "\n",
        "# open camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# get detections\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(frame, 0), dtype=tf.float32)\n",
        "    \n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {\n",
        "        key : value[0, :num_detections].numpy() for key, value in detections.items()\n",
        "    }\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype('int')\n",
        "\n",
        "    label_id_offset = 1\n",
        "    img_detections = frame.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        img_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'] + label_id_offset,\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=10,\n",
        "        min_score_thresh=0.7,\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "    \n",
        "    # display image\n",
        "    cv2.imshow('detector', cv2.resize(img_detections, (width, height)))\n",
        "    \n",
        "    # to cancel press \"q\"\n",
        "    if cv2.waitKey(10) & 0xff == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585bb4c8",
      "metadata": {
        "id": "585bb4c8"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3133d70d",
      "metadata": {
        "id": "3133d70d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d37fad-1a17-4055-e533-fdfa13a00b2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "SAVE_MODEL_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py')\n",
        "os.path.exists(SAVE_MODEL_SCRIPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b571ce60",
      "metadata": {
        "id": "b571ce60"
      },
      "outputs": [],
      "source": [
        "script = f'python {SAVE_MODEL_SCRIPT} \\\n",
        "--input_type=image_tensor \\\n",
        "--pipeline_config_path={files[\"PIPELINE_CONFIG\"]} \\\n",
        "--trained_checkpoint_dir={paths[\"CHECKPOINT_PATH\"]} \\\n",
        "--output_directory={paths[\"OUTPUT_PATH\"]}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fff388",
      "metadata": {
        "id": "84fff388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10806cac-1d25-4391-b078-ea425602f7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/exporter_main_v2.py --input_type=image_tensor --pipeline_config_path=Tensorflow/workspace/models/drone_ssd_mobnet_v4/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/drone_ssd_mobnet_v4 --output_directory=Tensorflow/workspace/models/drone_ssd_mobnet_v4/export\n"
          ]
        }
      ],
      "source": [
        "print(script)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{script}"
      ],
      "metadata": {
        "id": "RUoNtnIHJxMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a13417-d725-46be-8a85-c5cfdbc90403"
      },
      "id": "RUoNtnIHJxMs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-21 14:44:31.830506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:44:31.830616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:44:31.830634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-01-21 14:44:35.421529: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0121 14:44:35.513057 139666721373248 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0121 14:44:35.587244 139666721373248 deprecation.py:623] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f063006b250>, because it is not built.\n",
            "W0121 14:44:53.763169 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f063006b250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb94a490>, because it is not built.\n",
            "W0121 14:44:53.991824 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb94a490>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb8bc610>, because it is not built.\n",
            "W0121 14:44:53.992038 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb8bc610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb8bc970>, because it is not built.\n",
            "W0121 14:44:53.992143 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb8bc970>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb8bc910>, because it is not built.\n",
            "W0121 14:44:53.992240 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb8bc910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb952bb0>, because it is not built.\n",
            "W0121 14:44:53.992322 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb952bb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb952d60>, because it is not built.\n",
            "W0121 14:44:53.992396 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb952d60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb952040>, because it is not built.\n",
            "W0121 14:44:53.992465 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bb952040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb952c40>, because it is not built.\n",
            "W0121 14:44:53.992556 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb952c40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05d4490640>, because it is not built.\n",
            "W0121 14:44:53.992629 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05d4490640>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bbc04f70>, because it is not built.\n",
            "W0121 14:44:53.992698 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f05bbc04f70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbc93100>, because it is not built.\n",
            "W0121 14:44:53.992766 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbc93100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbc93cd0>, because it is not built.\n",
            "W0121 14:44:53.992835 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbc93cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bba9d490>, because it is not built.\n",
            "W0121 14:44:53.992910 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bba9d490>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9df340>, because it is not built.\n",
            "W0121 14:44:53.992980 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9df340>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9df0d0>, because it is not built.\n",
            "W0121 14:44:53.993050 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9df0d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9dfbb0>, because it is not built.\n",
            "W0121 14:44:53.993119 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9dfbb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbb3e100>, because it is not built.\n",
            "W0121 14:44:53.993187 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbb3e100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbb3e6a0>, because it is not built.\n",
            "W0121 14:44:53.993255 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbb3e6a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9db5b0>, because it is not built.\n",
            "W0121 14:44:53.993323 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9db5b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9db3d0>, because it is not built.\n",
            "W0121 14:44:53.993391 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9db3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9c4610>, because it is not built.\n",
            "W0121 14:44:53.993460 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9c4610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9ed8b0>, because it is not built.\n",
            "W0121 14:44:53.993550 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9ed8b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbb5340>, because it is not built.\n",
            "W0121 14:44:53.993622 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbb5340>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbbb5b20>, because it is not built.\n",
            "W0121 14:44:53.993690 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbbb5b20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbb5c10>, because it is not built.\n",
            "W0121 14:44:53.993758 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbb5c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbbb53d0>, because it is not built.\n",
            "W0121 14:44:53.993826 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbbb53d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9cf850>, because it is not built.\n",
            "W0121 14:44:53.993894 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb9cf850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9cf760>, because it is not built.\n",
            "W0121 14:44:53.993962 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9cf760>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb996b80>, because it is not built.\n",
            "W0121 14:44:53.994030 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb996b80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9c0640>, because it is not built.\n",
            "W0121 14:44:53.994099 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9c0640>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986a00>, because it is not built.\n",
            "W0121 14:44:53.994168 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986a00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9862b0>, because it is not built.\n",
            "W0121 14:44:53.994236 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb9862b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986cd0>, because it is not built.\n",
            "W0121 14:44:53.994313 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb986940>, because it is not built.\n",
            "W0121 14:44:53.994386 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb986940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986100>, because it is not built.\n",
            "W0121 14:44:53.994453 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb986100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbee2730>, because it is not built.\n",
            "W0121 14:44:53.994539 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbee2730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bba23640>, because it is not built.\n",
            "W0121 14:44:53.994611 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bba23640>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb99dc40>, because it is not built.\n",
            "W0121 14:44:53.994680 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bb99dc40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb99d5e0>, because it is not built.\n",
            "W0121 14:44:53.994747 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bb99d5e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbeec2e0>, because it is not built.\n",
            "W0121 14:44:53.994816 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbeec2e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbdf1bb0>, because it is not built.\n",
            "W0121 14:44:53.994890 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbdf1bb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbc2d370>, because it is not built.\n",
            "W0121 14:44:53.994958 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbc2d370>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbd8100>, because it is not built.\n",
            "W0121 14:44:54.011101 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05bbbd8100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbb7f130>, because it is not built.\n",
            "W0121 14:44:54.011241 139666721373248 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05bbb7f130>, because it is not built.\n",
            "W0121 14:45:14.010324 139666721373248 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/drone_ssd_mobnet_v4/export/saved_model/assets\n",
            "I0121 14:45:19.249255 139666721373248 builder_impl.py:797] Assets written to: Tensorflow/workspace/models/drone_ssd_mobnet_v4/export/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to Tensorflow/workspace/models/drone_ssd_mobnet_v4/export/pipeline.config\n",
            "I0121 14:45:20.206640 139666721373248 config_util.py:253] Writing pipeline config file to Tensorflow/workspace/models/drone_ssd_mobnet_v4/export/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b0595d",
      "metadata": {
        "id": "d3b0595d"
      },
      "source": [
        "# Export to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e5f3da",
      "metadata": {
        "id": "e4e5f3da"
      },
      "outputs": [],
      "source": [
        "script = f\"tensorflowjs_converter \\\n",
        "--input_format=tf_saved_model \\\n",
        "--output_node_names='\\\n",
        "detection_boxes,detection_classes,detection_features,\\\n",
        "detection_multiclass_scores,detection_scores,\\\n",
        "num_detections,raw_detection_boxes,raw_detection_scores' \\\n",
        "--output_format=tfjs_graph_model \\\n",
        "--signature_name=serving_default \\\n",
        "{os.path.join(paths['OUTPUT_PATH'], 'saved_model')} \\\n",
        "{paths['TFJS_PATH']}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685f901b",
      "metadata": {
        "id": "685f901b",
        "outputId": "f240db1e-616b-4157-b06f-8433cafc2224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow/workspace/models/drone_ssd_mobnet_v4/export/saved_model Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfjsexport\n"
          ]
        }
      ],
      "source": [
        "print(script)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{script}"
      ],
      "metadata": {
        "id": "kc43yRVQUmKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1d21c7-84e1-4b6b-c4df-ecfe47e80dc6"
      },
      "id": "kc43yRVQUmKJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: tensorflowjs_converter: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d56caf19",
      "metadata": {
        "id": "d56caf19"
      },
      "source": [
        "# Export to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee3c922d",
      "metadata": {
        "id": "ee3c922d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7aa7b18-584b-416a-baf0-e931d7e79c64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py')\n",
        "os.path.exists(TFLITE_SCRIPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddedd810",
      "metadata": {
        "id": "ddedd810"
      },
      "outputs": [],
      "source": [
        "script = f\"python {TFLITE_SCRIPT} \\\n",
        "--pipeline_config_path={files['PIPELINE_CONFIG']} \\\n",
        "--trained_checkpoint_dir={paths['CHECKPOINT_PATH']} \\\n",
        "--output_directory={paths['TFLITE_PATH']}\\\n",
        "\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a01759",
      "metadata": {
        "id": "b9a01759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ebb8bb-900d-4e4c-d2b2-e21d390813a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py --pipeline_config_path=Tensorflow/workspace/models/drone_ssd_mobnet_v4/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/drone_ssd_mobnet_v4 --output_directory=Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfliteexport\n"
          ]
        }
      ],
      "source": [
        "print(script)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{script}"
      ],
      "metadata": {
        "id": "S8x9b85HbWgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5679ebea-7d4a-456e-f43f-b6c3e49a406a"
      },
      "id": "S8x9b85HbWgp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-21 14:45:22.896110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:45:22.896211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:45:22.896230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-01-21 14:45:26.405375: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0121 14:45:31.873815 140505001311296 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc902397b80>, because it is not built.\n",
            "W0121 14:45:37.491929 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc902397b80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e93fcb50>, because it is not built.\n",
            "W0121 14:45:37.750027 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e93fcb50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94b9e80>, because it is not built.\n",
            "W0121 14:45:37.750240 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94b9e80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94b9910>, because it is not built.\n",
            "W0121 14:45:37.750348 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94b9910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e94b9cd0>, because it is not built.\n",
            "W0121 14:45:37.750432 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e94b9cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc902038dc0>, because it is not built.\n",
            "W0121 14:45:37.750511 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc902038dc0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc902038cd0>, because it is not built.\n",
            "W0121 14:45:37.750609 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc902038cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e9634190>, because it is not built.\n",
            "W0121 14:45:37.750686 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e9634190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e96345b0>, because it is not built.\n",
            "W0121 14:45:37.750759 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e96345b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9634730>, because it is not built.\n",
            "W0121 14:45:37.750830 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9634730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e9634880>, because it is not built.\n",
            "W0121 14:45:37.750900 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fc8e9634880>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9020964c0>, because it is not built.\n",
            "W0121 14:45:37.750968 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9020964c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc902096bb0>, because it is not built.\n",
            "W0121 14:45:37.751046 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc902096bb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e9505c40>, because it is not built.\n",
            "W0121 14:45:37.751115 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e9505c40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9540880>, because it is not built.\n",
            "W0121 14:45:37.751186 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9540880>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94f8df0>, because it is not built.\n",
            "W0121 14:45:37.751256 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94f8df0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94f8100>, because it is not built.\n",
            "W0121 14:45:37.751326 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94f8100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e927eca0>, because it is not built.\n",
            "W0121 14:45:37.751396 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e927eca0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e927e6a0>, because it is not built.\n",
            "W0121 14:45:37.751474 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e927e6a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e93099d0>, because it is not built.\n",
            "W0121 14:45:37.751557 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e93099d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9309280>, because it is not built.\n",
            "W0121 14:45:37.751637 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9309280>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94e92b0>, because it is not built.\n",
            "W0121 14:45:37.751710 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94e92b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9624040>, because it is not built.\n",
            "W0121 14:45:37.751780 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9624040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95ca3d0>, because it is not built.\n",
            "W0121 14:45:37.751850 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95ca3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95cadf0>, because it is not built.\n",
            "W0121 14:45:37.751921 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95cadf0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95ca4c0>, because it is not built.\n",
            "W0121 14:45:37.751996 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95ca4c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95ca070>, because it is not built.\n",
            "W0121 14:45:37.752068 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95ca070>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95f15b0>, because it is not built.\n",
            "W0121 14:45:37.752156 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e95f15b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95f1070>, because it is not built.\n",
            "W0121 14:45:37.752238 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e95f1070>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e9616910>, because it is not built.\n",
            "W0121 14:45:37.752316 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e9616910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9198af0>, because it is not built.\n",
            "W0121 14:45:37.752391 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e9198af0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9021963d0>, because it is not built.\n",
            "W0121 14:45:37.752465 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9021963d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc90208cf10>, because it is not built.\n",
            "W0121 14:45:37.752681 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc90208cf10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc970738580>, because it is not built.\n",
            "W0121 14:45:37.752780 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc970738580>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e910c130>, because it is not built.\n",
            "W0121 14:45:37.752855 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e910c130>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e910c6a0>, because it is not built.\n",
            "W0121 14:45:37.752928 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e910c6a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e910c7c0>, because it is not built.\n",
            "W0121 14:45:37.753006 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e910c7c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9021ccb80>, because it is not built.\n",
            "W0121 14:45:37.753078 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc9021ccb80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94a7640>, because it is not built.\n",
            "W0121 14:45:37.753149 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94a7640>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94a7b50>, because it is not built.\n",
            "W0121 14:45:37.753218 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e94a7b50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94a7c10>, because it is not built.\n",
            "W0121 14:45:37.753288 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e94a7c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e90fd160>, because it is not built.\n",
            "W0121 14:45:37.753365 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e90fd160>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e90fd220>, because it is not built.\n",
            "W0121 14:45:37.753435 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e90fd220>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e90fd730>, because it is not built.\n",
            "W0121 14:45:37.800296 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc8e90fd730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e90fd7f0>, because it is not built.\n",
            "W0121 14:45:37.800498 140505001311296 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fc8e90fd7f0>, because it is not built.\n",
            "W0121 14:45:54.039927 140505001311296 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfliteexport/saved_model/assets\n",
            "I0121 14:45:59.096026 140505001311296 builder_impl.py:797] Assets written to: Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfliteexport/saved_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef26cc79",
      "metadata": {
        "id": "ef26cc79"
      },
      "outputs": [],
      "source": [
        "INPUT_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea98bc9",
      "metadata": {
        "id": "3ea98bc9"
      },
      "outputs": [],
      "source": [
        "script = f\"tflite_convert \\\n",
        "--saved_model_dir={INPUT_MODEL} \\\n",
        "--output_file={TFLITE_MODEL} \\\n",
        "--input_shapes=1,320,320,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays=\\\n",
        "'TFLite_Detection_PostProcess',\\\n",
        "'TFLite_Detection_PostProcess:1',\\\n",
        "'TFLite_Detection_PostProcess:2',\\\n",
        "'TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927f36ba",
      "metadata": {
        "id": "927f36ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf4151c-ee48-4eaa-c321-8ef947ffba13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tflite_convert --saved_model_dir=Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfliteexport/saved_model --output_file=Tensorflow/workspace/models/drone_ssd_mobnet_v4/tfliteexport/saved_model/detect.tflite --input_shapes=1,320,320,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
          ]
        }
      ],
      "source": [
        "print(script)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{script}"
      ],
      "metadata": {
        "id": "v71tdFWsbeby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baec462-2630-4b2a-ab47-8dba7ebe17ab"
      },
      "id": "v71tdFWsbeby",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-21 14:46:02.433187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:46:02.433286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-21 14:46:02.433304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-01-21 14:46:05.456968: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-01-21 14:46:14.109532: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
            "2023-01-21 14:46:14.109586: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c36635",
      "metadata": {
        "id": "d0c36635"
      },
      "source": [
        "# Zip model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cddbc22",
      "metadata": {
        "id": "8cddbc22"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8nQNKo8m2CA"
      },
      "id": "S8nQNKo8m2CA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mj2dnCQYfD-0",
        "9354e180",
        "55bbe7cd",
        "3b1f4ec4",
        "abba06ed",
        "2efc5ab8"
      ]
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}